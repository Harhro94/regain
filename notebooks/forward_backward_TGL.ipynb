{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward-backward splitting for time-varying graphical lasso\n",
    "This notebook shows how to minimise the time-varying graphical lasso with element-wise penalty norms across time-points.\n",
    "\n",
    "First of all, as always, let's create a bunch of data.\n",
    "For this task, we generate eah variable to change according to a certain behaviour which can be described as evolution via tigonometric functions, such as `sin` and `cos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial.distance import squareform\n",
    "from regain import datasets, utils\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "\n",
    "from skopt.searchcv import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(7)\n",
    "\n",
    "# fs = 10e3\n",
    "# N = 100\n",
    "# amp = 2*np.sqrt(2)\n",
    "# freq = 1.0\n",
    "# noise_power = 0.001 * fs / 2\n",
    "# time = np.arange(N) / fs\n",
    "# z = amp*np.sin(2*np.pi*freq*time)\n",
    "# z += np.random.normal(scale=np.sqrt(noise_power), size=time.shape)\n",
    "# plt.plot(z);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = 4\n",
    "\n",
    "# x = np.tile(np.linspace(0, T-1, T), (n_interactions, 1))\n",
    "# zz = amp * signal.square(2 * np.pi * freq * x + phase, duty=.5)\n",
    "# plt.plot(x.T, zz.T);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the data starting from the inverse covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.datasets import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_sin(n_dim_obs, n_dim_lat, T, shape='smooth', closeness=1,\n",
    "             normalize=False):\n",
    "    upper_idx = np.triu_indices(n_dim_obs, 1)\n",
    "    n_interactions = len(upper_idx[0])\n",
    "    x = np.tile(np.linspace(0, (T-1.) / closeness, T), (n_interactions, 1))\n",
    "    phase = np.random.rand(n_interactions, 1)\n",
    "    freq = np.random.rand(n_interactions, 1) - .250\n",
    "    A = (np.random.rand(n_interactions, 1) + 2) / 2.\n",
    "\n",
    "    if shape == 'smooth':\n",
    "        y = A * np.sin(2. * np.pi * freq * x + phase)\n",
    "    else:\n",
    "        y = A * signal.square(2 * np.pi * freq * x + phase, duty=.5)\n",
    "\n",
    "    # threshold\n",
    "    y = np.maximum(y, 0)\n",
    "\n",
    "    Y = np.array([squareform(y[:, j]) + np.diag(np.sum(squareform(y[:, j]), axis=1))\n",
    "                  for j in range(y.shape[1])])\n",
    "\n",
    "    if normalize:\n",
    "        map(normalize_matrix, Y)  # in place\n",
    "    assert positive_definite(Y)\n",
    "\n",
    "    return Y, Y, np.zeros_like(Y)\n",
    "\n",
    "data = {}\n",
    "np.random.seed(7)\n",
    "data['square'] = datasets.make_dataset(n_samples=n_samples, n_dim_obs=n_dim_obs, n_dim_lat=0, T=T,\n",
    "                             time_on_axis='last',\n",
    "                             mode=make_sin, shape='square', closeness=2.4, normalize=1)\n",
    "\n",
    "\n",
    "plt.step(np.array([squareform(y, checks=None) for y in data['square'].thetas]), '-|');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "\n",
    "# square\n",
    "n_samples = 100\n",
    "n_dim_obs = 20\n",
    "T = 10\n",
    "\n",
    "data = {}\n",
    "data['square'] = datasets.make_dataset(n_samples=n_samples, n_dim_obs=n_dim_obs, n_dim_lat=0, T=T,\n",
    "                             time_on_axis='last',\n",
    "                             mode='sin', shape='square', closeness=2.4, normalize=1)\n",
    "\n",
    "# smooth\n",
    "n_samples = 100\n",
    "n_dim_obs = 20\n",
    "T = 10\n",
    "\n",
    "data['smooth'] = datasets.make_dataset(n_samples=n_samples, n_dim_obs=n_dim_obs, n_dim_lat=0, T=T,\n",
    "                             time_on_axis='last',\n",
    "                             mode='sin', shape='smooth', closeness=2.4, normalize=1)\n",
    "\n",
    "plt.step(np.array([squareform(y, checks=None) for y in data['square'].thetas]), '-|');\n",
    "# plt.savefig(\"/home/fede/Dropbox/Latent variables networks/forward backward time varying graphical lasso/smooth_signal.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = data.data\n",
    "# X_tr, X_ts = train_test_split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "from regain import update_rules; reload(update_rules);\n",
    "from regain.forward_backward import time_graph_lasso_; reload(time_graph_lasso_)\n",
    "\n",
    "from sklearn.covariance import GraphLasso, GraphLassoCV\n",
    "import sys; sys.path.append(\"/home/fede/src/TVGL\")\n",
    "import inferGraphL1; reload(inferGraphL1)\n",
    "import inferGraphL2; reload(inferGraphL2)\n",
    "import TVGL; reload(TVGL)\n",
    "\n",
    "# use:\n",
    "# beta = 2.1, norm = 1\n",
    "# beta = 5.05, norm = 2\n",
    "# prepare dataframe for results\n",
    "\n",
    "methods = ['TGL-FB ($\\ell_{21}$)', 'TGL-FB ($\\ell_1$)', 'GL', 'TVGL ($\\ell_{21}$)', 'TVGL ($\\ell_1$)']\n",
    "\n",
    "scores = sorted(['iter', 'accuracy',  'average_precision',  'balanced_accuracy','f1','false_omission_rate','fdr',\n",
    "                 'fn',  'fp',  'precision',  'prevalence',  'recall',  'specificity',  'tn',  'tp'])\n",
    "evolution = sorted(['square', 'smooth'])\n",
    "\n",
    "rows = methods\n",
    "cols = pd.MultiIndex.from_product([evolution, scores], names=('evolution', 'score'))\n",
    "# rows = pd.MultiIndex.from_product([methods, n_times], names=('method','time'))\n",
    "\n",
    "dff = pd.DataFrame(columns=cols, index=rows)\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_performance(beta=1, alpha=1, evolution='square'):\n",
    "    X = data[evolution].data\n",
    "    \n",
    "    error_function = partial(utils.structure_error, data[evolution].thetas,\n",
    "                             no_diagonal=0, thresholding=1, eps=1e-4)\n",
    "\n",
    "    tglfb = time_graph_lasso_.TimeGraphLassoForwardBackward(\n",
    "        verbose=0, gamma=1, alpha=alpha, beta=beta,\n",
    "        delta=1e-8, choose='lamda', lamda_criterion='c',\n",
    "        lamda=1, tol=1e-5, eps=0.9,\n",
    "        time_norm=2, max_iter=300, time_on_axis='last').fit(X)\n",
    "#     print(tglfb.alpha_max(X))\n",
    "#     return\n",
    "    res = error_function(tglfb.precision_)\n",
    "    res['iter'] = tglfb.n_iter_\n",
    "    dff.loc['TGL-FB ($\\ell_{21}$)', idx[evolution, :]] = [res[x] for x in scores]\n",
    "    \n",
    "    tglfb = tglfb.set_params(time_norm=1).fit(X)\n",
    "    res = error_function(tglfb.precision_)\n",
    "    res['iter'] = tglfb.n_iter_\n",
    "    dff.loc['TGL-FB ($\\ell_1$)', idx[evolution, :]] = [res[x] for x in scores]\n",
    "\n",
    "    gl = GraphLasso(alpha=0.05)\n",
    "#     gl = GraphLassoCV(alphas=list(np.logspace(-1, 0, 100)))\n",
    "    precision_gl = np.array([gl.fit(x).precision_.copy() for x in X.transpose(2,0,1)])\n",
    "    res = error_function(precision_gl)\n",
    "    res['iter'] = gl.n_iter_\n",
    "    dff.loc['GL', idx[evolution, :]] = [res[x] for x in scores]\n",
    "    \n",
    "    thetaSet, empCovSet, status, gvx = TVGL.TVGL(\n",
    "        np.vstack(X.transpose(2,0,1)), X.shape[0],\n",
    "        lamb=gl.alpha, beta=tglfb.beta, indexOfPenalty=2, verbose=False)\n",
    "\n",
    "    res = error_function(np.array(thetaSet))\n",
    "    res['iter'] = gvx.n_iter_\n",
    "    dff.loc['TVGL ($\\ell_{21}$)', idx[evolution, :]] = [res[x] for x in scores]\n",
    "    \n",
    "    thetaSet, empCovSet, status, gvx = TVGL.TVGL(\n",
    "        np.vstack(X.transpose(2,0,1)), X.shape[0],\n",
    "        lamb=gl.alpha, beta=tglfb.beta, indexOfPenalty=1, verbose=False)\n",
    "    res = error_function(np.array(thetaSet))\n",
    "    res['iter'] = gvx.n_iter_\n",
    "    dff.loc['TVGL ($\\ell_1$)', idx[evolution, :]] = [res[x] for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "run_performance(beta=1.09, alpha=0.55, evolution='square')\n",
    "# run_performance(beta=5, alpha=0.53, evolution='smooth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = ['accuracy', 'average_precision', 'balanced_accuracy', 'f1', 'iter']\n",
    "# dff['smooth'].sort_values(\"f1\", ascending=False)#[ss]\n",
    "dff['square'].sort_values(\"f1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dff.to_pickle(\"results_25_04_18.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evolution = 'square'; alpha = 0.55; beta = 1.09\n",
    "# evolution = 'smooth'; alpha = 0.53; beta = 5\n",
    "from regain import prox; reload(prox)\n",
    "from regain import norm; reload(norm)\n",
    "reload(time_graph_lasso_)\n",
    "X = data[evolution].data\n",
    "\n",
    "\n",
    "tglfb_square = time_graph_lasso_.TimeGraphLassoForwardBackward(\n",
    "    verbose=2, gamma=1, alpha=alpha, beta=beta,\n",
    "    delta=1e-8, choose='lamda', lamda_criterion='c',\n",
    "    lamda=1, tol=1e-5, eps=0.9, return_history=True,\n",
    "    time_norm=1, max_iter=300, time_on_axis='last').fit(X)\n",
    "\n",
    "tglfb_smooth = time_graph_lasso_.TimeGraphLassoForwardBackward(\n",
    "    verbose=2, gamma=1, alpha=alpha, beta=beta,\n",
    "    delta=1e-8, choose='lamda', lamda_criterion='c',\n",
    "    lamda=1, tol=1e-5, eps=0.9, return_history=True,\n",
    "    time_norm=2, max_iter=300, time_on_axis='last').fit(X)\n",
    "\n",
    "# thetaSet, empCovSet, status, gvx_square = TVGL.TVGL(\n",
    "#     np.vstack(X.transpose(2,0,1)), X.shape[0],\n",
    "#     lamb=alpha, beta=beta, indexOfPenalty=2, verbose=False, epsAbs=1e-5)\n",
    "# thetaSet, empCovSet, status, gvx_smooth = TVGL.TVGL(\n",
    "#     np.vstack(X.transpose(2,0,1)), X.shape[0],\n",
    "#     lamb=alpha, beta=beta, indexOfPenalty=1, verbose=False, epsAbs=1e-5)\n",
    "\n",
    "plt.title(\"Evolution: %s\" % evolution)\n",
    "plt.semilogy([x.rnorm for x in tglfb_smooth.history_], label='TVGL $\\ell_{21}$')\n",
    "plt.semilogy([x.rnorm for x in tglfb_square.history_], label='TGL-FB $\\ell_1$')\n",
    "plt.semilogy([x for x in gvx_square.history_], label='TVGL $\\ell_1$')\n",
    "plt.semilogy([x for x in gvx_smooth.history_], label='TVGL $\\ell_{21}$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Evolution: %s\" % evolution)\n",
    "plt.plot([x.rnorm for x in tglfb_smooth.history_], label='TVGL $\\ell_{21}$')\n",
    "plt.plot([x.rnorm for x in tglfb_square.history_], label='TGL-FB $\\ell_1$')\n",
    "plt.plot([x for x in gvx_square.history_], label='TVGL $\\ell_1$')\n",
    "plt.plot([x for x in gvx_smooth.history_], label='TVGL $\\ell_{21}$')\n",
    "plt.legend()\n",
    "# plt.xlim([0,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "error_function = partial(utils.structure_error, data[evolution].thetas,\n",
    "                             no_diagonal=0, thresholding=1, eps=1e-4)\n",
    "\n",
    "res = error_function(tglfb.precision_)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tglfb.n_iter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.abs(tglfb.precision_).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BayesOptimisation\n",
    "Since we have lots of hyper-parameters, we rely on a Bayesian optimisation procedure in order to select the best hyper-parameters, treating the scoring function of our algorithm as a black-box for the gaussian process underlying the Bayesian optimisation.\n",
    "\n",
    "Such procedure is performed via the `scikit-optimize` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain import utils; reload(utils)\n",
    "from regain import prox; reload(prox);\n",
    "from regain.forward_backward import time_graph_lasso_; reload(time_graph_lasso_)\n",
    "\n",
    "from skopt import searchcv; reload(searchcv)\n",
    "\n",
    "X = data['square'].data\n",
    "\n",
    "domain = {'alpha': Real(1e-1, 3, prior='uniform'),\n",
    "          'beta': Real(1e-1, 1e1, prior='uniform'),\n",
    "#           'time_norm': Categorical([1, 2])\n",
    "#           'eps': Categorical([0.5, 0.7, 0.8, 0.9])\n",
    "         }\n",
    "\n",
    "mdl = time_graph_lasso_.TimeGraphLassoForwardBackward(\n",
    "    verbose=0, tol=1e-5, max_iter=200, gamma=1, beta=2.1, time_norm=1,\n",
    "    time_on_axis='last', alpha=.77,\n",
    "    delta=1e-8, choose='lamda', lamda_criterion='c', eps=0.9)\n",
    "    \n",
    "cv = ShuffleSplit(5, test_size=0.2)\n",
    "    \n",
    "bscv = searchcv.BayesSearchCV(\n",
    "    mdl, domain, n_iter=100, cv=cv, verbose=0, n_jobs=1, iid=True, n_points=3,\n",
    "    error_score=-3e5)\n",
    "\n",
    "def on_step(optim_result):\n",
    "    score = bscv.best_score_\n",
    "#     print(\"best score: %s\" % score)\n",
    "\n",
    "# bscv.fit(X, callback=on_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bscv_smooth.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# searchCV on smooth data set\n",
    "domain = {'alpha': Real(0.1, 1, prior='uniform'),\n",
    "          'beta': Real(0.5, 5, prior='uniform'),\n",
    "#           'time_norm': Categorical([1, 2])\n",
    "#           'eps': Categorical([0.5, 0.7, 0.8, 0.9])\n",
    "         }\n",
    "bscv_smooth = searchcv.BayesSearchCV(\n",
    "    mdl, domain, n_iter=300, cv=cv, verbose=0, n_jobs=1, iid=True, n_points=3,\n",
    "    error_score=-3e5)\n",
    "\n",
    "def on_step(optim_result):\n",
    "    score = bscv_smooth.best_score_\n",
    "#     print(\"best score: %s\" % score)\n",
    "\n",
    "ltgl.fit(data_grid, callback=on_step)\n",
    "# mdl.fit(data_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.structure_error(data.thetas, mdl.precision_, no_diagonal=0, thresholding=1, eps=1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdl = ltgl.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mdl.score(data_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ltgl.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ltgl.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bscv_smooth.fit(data['smooth'].data, callback=on_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "As for the hyper-parameters tuning, one may choose to fix a grid of parameters and select the best ones.\n",
    "For this we can use `GridSearchCV`, from the `scikit-learn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid=dict(alpha=np.logspace(-2,0,3), beta=np.logspace(-2,0,3),\n",
    "                time_norm=[1, 2])\n",
    "\n",
    "mdl = time_graph_lasso_.TimeGraphLassoForwardBackward(\n",
    "    verbose=0, time_on_axis='last')\n",
    "    \n",
    "cv = ShuffleSplit(2, test_size=0.2)\n",
    "ltgl = GridSearchCV(mdl, param_grid, cv=cv, verbose=1)\n",
    "ltgl.fit(data_grid)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
