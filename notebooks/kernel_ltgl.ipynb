{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Latent Variable Time-varying Graphical Lasso\n",
    "More than 1-Markovian!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, division\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from sklearn.datasets import make_sparse_spd_matrix\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.utils.extmath import squared_norm\n",
    "from sklearn.covariance import GraphLasso, empirical_covariance\n",
    "from sklearn.datasets.base import Bunch\n",
    "from sklearn.model_selection import GridSearchCV, ShuffleSplit\n",
    "from sklearn.gaussian_process import kernels\n",
    "\n",
    "from regain import prox; reload(prox)\n",
    "from regain.covariance import time_graph_lasso_; reload(time_graph_lasso_);\n",
    "from regain.covariance import latent_time_graph_lasso_; reload(latent_time_graph_lasso_);\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regainpr.bayesian import wishart_process_; reload(wishart_process_)\n",
    "from regainpr.bayesian import stats; reload(stats)\n",
    "\n",
    "from regainpr.covariance import kernel_time_graph_lasso_; reload(kernel_time_graph_lasso_);\n",
    "from regainpr.covariance import kernel_latent_time_graph_lasso_; reload(kernel_latent_time_graph_lasso_);\n",
    "from regainpr import datasets; reload(datasets);\n",
    "from regainpr import utils; reload(utils);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tgl_results(data_grid, K, **params):\n",
    "    mdl = time_graph_lasso_.TimeGraphLasso(\n",
    "        time_on_axis='last', assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "        max_iter=500, rho=1./ np.sqrt(data_grid.shape[0]))\n",
    "\n",
    "    tic = time.time()\n",
    "    ll = mdl.set_params(**params).fit(data_grid)\n",
    "    tac = time.time()\n",
    "    iterations = ll.n_iter_\n",
    "    MSE_precision = utils.error_norm(K, ll.precision_)\n",
    "    ss = utils.structure_error(K, ll.precision_)#, thresholding=1, eps=1e-5)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               MSE_precision=MSE_precision,\n",
    "               likelihood=mdl.score(data_grid),\n",
    "               estimator=ll)\n",
    "    res = dict(res, **ss)\n",
    "    return res\n",
    "\n",
    "def ktgl_results(data_grid, K, **params):\n",
    "    mdl = kernel_time_graph_lasso_.KernelTimeGraphLasso(\n",
    "        time_on_axis='last', assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "        max_iter=500, rho=1./ np.sqrt(data_grid.shape[0]), update_rho_options=dict(mu=5))\n",
    "\n",
    "    tic = time.time()\n",
    "    ll = mdl.set_params(**params).fit(data_grid)\n",
    "    tac = time.time()\n",
    "    iterations = ll.n_iter_\n",
    "    MSE_precision = utils.error_norm(K, ll.precision_)\n",
    "    ss = utils.structure_error(K, ll.precision_)#, thresholding=1, eps=1e-5)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               MSE_precision=MSE_precision,\n",
    "               likelihood=mdl.score(data_grid),\n",
    "               estimator=ll)\n",
    "    res = dict(res, **ss)\n",
    "    return res\n",
    "\n",
    "def new_ktgl_results(data_list, K, **params):\n",
    "    mdl = kernel_time_graph_lasso_.NewKernelTimeGraphLasso(\n",
    "        alpha=0.5, psi='laplacian',\n",
    "        assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "        max_iter=500, rho=1./ np.sqrt(data_grid.shape[0]), update_rho_options=dict(mu=5),\n",
    "        kernel=partial(kernels.ExpSineSquared, periodicity=np.pi), length_scale=2)\n",
    "\n",
    "    X = np.vstack(data_list)\n",
    "    y = np.array([\n",
    "        np.ones(x.shape[0]) *i for i, x in enumerate(data_list)]).flatten().astype(int)\n",
    "    \n",
    "    tic = time.time()\n",
    "    ll = mdl.set_params(**params).fit(X, y)\n",
    "    tac = time.time()\n",
    "    iterations = ll.n_iter_\n",
    "    MSE_precision = utils.error_norm(K, ll.precision_)\n",
    "    ss = utils.structure_error(K, ll.precision_)#, thresholding=1, eps=1e-5)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               MSE_precision=MSE_precision,\n",
    "               likelihood=mdl.score(X, y),\n",
    "               estimator=ll)\n",
    "    res = dict(res, **ss)\n",
    "    return res\n",
    "\n",
    "def kltgl_results(data_grid, K, K_obs, ells, **params):\n",
    "    mdl = kernel_latent_time_graph_lasso_.KernelLatentTimeGraphLasso(\n",
    "        time_on_axis='last', assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "        max_iter=1000, rho=1./ np.sqrt(data_grid.shape[0]),\n",
    "        update_rho_options=dict(mu=5))\n",
    "\n",
    "    tic = time.time()\n",
    "    ll = mdl.set_params(**params).fit(data_grid)\n",
    "    tac = time.time()\n",
    "    iterations = ll.n_iter_\n",
    "    ss = utils.structure_error(K, ll.precision_)\n",
    "    MSE_observed = utils.error_norm(K_obs, ll.precision_ - ll.latent_)\n",
    "    MSE_precision = utils.error_norm(K, ll.precision_, upper_triangular=True)\n",
    "    MSE_latent = utils.error_norm(ells, ll.latent_)\n",
    "    mean_rank_error = utils.error_rank(ells, ll.latent_)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               note=None,\n",
    "               estimator=ll,\n",
    "               likelihood=mdl.score(data_grid),\n",
    "              latent=ll.latent_)\n",
    "\n",
    "    res = dict(res, **ss)\n",
    "    return res\n",
    "\n",
    "def new_kltgl_results(data_list, K, K_obs, ells, **params):\n",
    "    mdl = kernel_latent_time_graph_lasso_.NewKernelLatentTimeGraphLasso(\n",
    "        alpha=0.5, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "        max_iter=500, rho=1./ np.sqrt(data_grid.shape[0]), update_rho_options=dict(mu=5),\n",
    "        kernel_psi=partial(kernels.ExpSineSquared, periodicity=np.pi), length_scale_psi=2,\n",
    "        kernel_phi=partial(kernels.ExpSineSquared, periodicity=np.pi), length_scale_phi=2,)\n",
    "\n",
    "    X = np.vstack(data_list)\n",
    "    y = np.array([\n",
    "        np.ones(x.shape[0]) *i for i, x in enumerate(data_list)]).flatten().astype(int)\n",
    "\n",
    "    tic = time.time()\n",
    "    ll = mdl.set_params(**params).fit(X,y)\n",
    "    tac = time.time()\n",
    "    iterations = ll.n_iter_\n",
    "    ss = utils.structure_error(K, ll.precision_)\n",
    "    MSE_observed = utils.error_norm(K_obs, ll.precision_ - ll.latent_)\n",
    "    MSE_precision = utils.error_norm(K, ll.precision_, upper_triangular=True)\n",
    "    MSE_latent = utils.error_norm(ells, ll.latent_)\n",
    "    mean_rank_error = utils.error_rank(ells, ll.latent_)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               MSE_precision=MSE_precision,\n",
    "               MSE_observed=MSE_observed,\n",
    "               MSE_latent=MSE_latent,\n",
    "               mean_rank_error=mean_rank_error,\n",
    "               note=None,\n",
    "               estimator=ll,\n",
    "               likelihood=mdl.score(X,y),\n",
    "              latent=ll.latent_)\n",
    "\n",
    "    res = dict(res, **ss)\n",
    "    return res\n",
    "\n",
    "def wp_results(data_grid, K, **params):\n",
    "    n_iter=1000\n",
    "    mdl = wishart_process_.WishartProcess(\n",
    "        time_on_axis='last', verbose=True, n_iter=n_iter)\n",
    "\n",
    "    tic = time.time()\n",
    "    ll = mdl.fit(data_grid)\n",
    "    tac = time.time()\n",
    "    \n",
    "#     mdl.likelihood(wp.D_map)\n",
    "#     mdl.loglikes_after_burnin.max()\n",
    "    mdl.store_precision = True\n",
    "\n",
    "    iterations = n_iter\n",
    "    print(\"before: {}\".format(positive_definite(ll.precision_)))\n",
    "    ss = utils.structure_error(K, ll.precision_, thresholding=False, eps=1e-3)\n",
    "    print(\"after: {}\".format(positive_definite(ll.precision_)))\n",
    "    MSE_precision = utils.error_norm(K, ll.precision_, upper_triangular=True)\n",
    "\n",
    "    res = dict(n_dim_obs=K.shape[1],\n",
    "               time=tac-tic,\n",
    "               iterations=iterations,\n",
    "               MSE_precision=MSE_precision,\n",
    "               estimator=ll,\n",
    "               likelihood=mdl.score(data_grid))\n",
    "\n",
    "    res = dict(res, **ss)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting 1\n",
    "n_samples = 100\n",
    "T = 10\n",
    "n_dim_obs = 5\n",
    "\n",
    "k = (n_dim_obs, T)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "reload(datasets)\n",
    "data = {(dim, T) : datasets.make_dataset(\n",
    "    mode='sin', shape='smooth',\n",
    "    update_theta='l2', normalize_starting_matrices=False,\n",
    "    n_samples=n_samples, n_dim_lat=0, n_dim_obs=dim,  T=T, epsilon=1e-1,\n",
    "    proportional=True, degree=2, keep_sparsity=True)\n",
    "    for dim in [n_dim_obs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting 2 - sample from GPs\n",
    "n_samples = 100\n",
    "T = 10\n",
    "n_dim_obs = 10\n",
    "\n",
    "k = (n_dim_obs, T)\n",
    "\n",
    "np.random.seed(0)   \n",
    "\n",
    "reload(datasets)\n",
    "data = {(dim, T) : datasets.make_dataset(\n",
    "    mode='gp', n_samples=n_samples, n_dim_lat=1, n_dim_obs=dim,  T=T, epsilon=0.4)\n",
    "    for dim in [n_dim_obs]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentual of non-zero components at each time: [0.72, 0.68, 0.7, 0.66, 0.7, 0.66, 0.66, 0.72, 0.68, 0.74]\n",
      "Percentual of total non-zero components: 0.692\n"
     ]
    }
   ],
   "source": [
    "# info on the data set\n",
    "K = data[k].thetas\n",
    "print (\"Percentual of non-zero components at each time: {}\".format(\n",
    "    [(i!=0).sum() / i.size for i in K]))\n",
    "\n",
    "print (\"Percentual of total non-zero components: {}\".format(\n",
    "    (K != 0).sum() / (n_dim_obs ** 2 * T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataframe for results\n",
    "n_dims = [n_dim_obs]\n",
    "n_times = [T]\n",
    "methods = ['TGL', 'KTGL', 'NKTGL', 'KLTGL', 'NKLTGL', 'WP']\n",
    "scores = sorted([\n",
    "    \"MSE_precision\", \"MSE_observed\", \"MSE_latent\", 'estimator', \"mean_rank_error\",\n",
    "    'time', 'iterations', 'precision', 'recall', 'accuracy', 'balanced_accuracy',\n",
    "    'f1', 'npv', 'prevalence', 'miss_rate', 'likelihood',\n",
    "    'specificity', 'plr', 'nlr'])\n",
    "\n",
    "cols = pd.MultiIndex.from_product([scores, n_dims], names=('score', 'dim'))\n",
    "rows = pd.MultiIndex.from_product([methods, n_times], names=('method', 'time'))\n",
    "\n",
    "dff = pd.DataFrame(columns=cols, index=rows)\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = 0.5\n",
    "rng = np.full(T-1, 1000)\n",
    "kernel_phi = np.diag(rng,1) +np.diag(rng,-1) + np.eye(T)\n",
    "kernel_phi = np.full((T ,T), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import kernels\n",
    "rbf = kernels.RBF(length_scale=0.5)\n",
    "expsin = kernels.ExpSineSquared(periodicity=np.pi, length_scale=2)\n",
    "kernel = expsin(np.arange(T)[:,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start with: dim=10, T=10 (it 0)\n",
      "starting WP ...\r"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 't_mvn_logpdf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-157-8c5572fbafcf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"starting WP ...\\r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwp_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0mdff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'WP'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-156-c7527b9bd4b7>\u001b[0m in \u001b[0;36mwp_results\u001b[0;34m(data_grid, K, **params)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m     \u001b[0mll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmdl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m     \u001b[0mtac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/fede/src/fdtomasi/regain-private/regainpr/bayesian/wishart_process_.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocation_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# put time last\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mkern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlikelihood\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_mvn_logpdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mn_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 't_mvn_logpdf'"
     ]
    }
   ],
   "source": [
    "# setting 1\n",
    "alpha = 0.6\n",
    "# beta = kernel[0,1]\n",
    "\n",
    "for i, (k, res) in enumerate(sorted(data.items())[:5]):\n",
    "    dim = k[0]\n",
    "    print(\"Start with: dim=%d, T=%d (it %d)\" % (k[0],k[1], i))\n",
    "    data_list = res.data\n",
    "    K = res.thetas\n",
    "    K_obs = res.thetas_observed\n",
    "    ells = res.ells\n",
    "    data_grid = np.array(data_list).transpose(1,2,0)  # to use it later for grid search\n",
    "\n",
    "    print(\"starting WP ...\\r\", end='')\n",
    "    res = wp_results(data_grid, K)\n",
    "    dff.loc[idx['WP', k[1]], idx[:, k[0]]] = [res.get(x,None) for x in scores]\n",
    "    \n",
    "    continue\n",
    "    \n",
    "    print(\"starting TGL ...\\r\", end='')\n",
    "    res = tgl_results(data_grid, K, beta=beta, alpha=alpha)\n",
    "    dff.loc[idx['TGL', k[1]], idx[:, k[0]]] = [res.get(x,None) for x in scores]\n",
    "    \n",
    "    print(\"starting KTGL ...\\r\", end='')\n",
    "    res = ktgl_results(data_grid, K, kernel=kernel, alpha=alpha)\n",
    "    dff.loc[idx['KTGL', k[1]], idx[:, k[0]]] = [res.get(x,None) for x in scores]\n",
    "    \n",
    "    print(\"starting NKTGL ...\\r\", end='')\n",
    "    res = new_ktgl_results(data_list, K, alpha=alpha, length_scale=0.4)\n",
    "    dff.loc[idx['NKTGL', k[1]], idx[:, k[0]]] = [res.get(x,None) for x in scores]\n",
    "    \n",
    "    print(\"starting KLTGL ...\\r\", end='')\n",
    "    res = kltgl_results(data_grid, K, K_obs, ells, kernel_psi=kernel,\n",
    "                        kernel_phi=kernel_phi, alpha=alpha)\n",
    "    dff.loc[idx['KLTGL', k[1]], idx[:, k[0]]] = [res.get(x,None) for x in scores]\n",
    "    \n",
    "    print(\"starting NKLTGL ...\\r\", end='')\n",
    "    res = new_kltgl_results(data_list, K,  K_obs, ells, alpha=alpha, length_scale_psi=0.4,\n",
    "                           length_scale_phi=10,\n",
    "                            kernel_phi=partial(kernels.ConstantKernel,constant_value=20))\n",
    "    dff.loc[idx['NKLTGL', k[1]], idx[:, k[0]]] = [res.get(x,None) for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mm = dff.xs(n_dim_obs, level='dim', axis=1).xs(T, level='time')\n",
    "# mm['likelihood']\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from regain.utils import positive_definite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_definite(mm.loc[\"WP\", 'estimator'].precision_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.57091563e-15,  3.87091327e-03,  2.09336897e-01,  5.89960784e-01,\n",
       "        9.15816353e-01,  3.21458013e+00,  4.24125047e+00,  7.54805965e+00,\n",
       "        9.02479559e+00,  1.29356205e+01])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import linalg\n",
    "linalg.eigvalsh(mm.loc[\"WP\", 'estimator'].precision_[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6648.427421079336"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = kernel_time_graph_lasso_.KernelTimeGraphLasso(\n",
    "    time_on_axis='last', assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "    max_iter=500, rho=1./ np.sqrt(data_grid.shape[0]), update_rho_options=dict(mu=5))\n",
    "mdl.fit(data_grid)\n",
    "mdl.score(data_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(data_list)\n",
    "y = np.array([np.ones(x.shape[0]) *i for i, x in enumerate(data_list)]).flatten().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6664.273982392405"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(prox)\n",
    "reload(time_graph_lasso_)\n",
    "reload(kernel_time_graph_lasso_);\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from skopt.optimizer import optimizer; reload(optimizer)\n",
    "from skopt import searchcv; reload(searchcv)\n",
    "from skopt.space import Categorical\n",
    "# include below until https://github.com/scikit-optimize/scikit-optimize/issues/718 is resolved\n",
    "class BayesSearchCV(searchcv.BayesSearchCV):\n",
    "    def _run_search(self, x): raise BaseException('Use newer skopt')\n",
    "\n",
    "mdl = kernel_time_graph_lasso_.NewKernelTimeGraphLasso(\n",
    "    alpha=0.5, psi='laplacian',\n",
    "    assume_centered=0, verbose=0, rtol=1e-5, tol=1e-5,\n",
    "    max_iter=500, rho=1./ np.sqrt(data_grid.shape[0]), update_rho_options=dict(mu=5),\n",
    "    kernel=partial(kernels.ExpSineSquared, periodicity=np.pi), length_scale=2)\n",
    "\n",
    "bscv = BayesSearchCV(mdl, search_spaces={\n",
    "        'alpha': (1e-4, 1e+1, 'log-uniform'),  \n",
    "        'length_scale': (1e-4, 1e+1, 'log-uniform'),\n",
    "#         'kernel': Categorical([partial(kernels.ExpSineSquared, periodicity=np.pi),\n",
    "#                                kernels.RBF]),  # categorical parameter\n",
    "    },\n",
    "    n_iter=50, n_points=3, cv=StratifiedKFold(3))\n",
    "\n",
    "bscv.fit(X, y)\n",
    "bscv.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 0.5792194050871016, 'length_scale': 0.38781388320536275}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bscv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(wishart_process_)\n",
    "wp = wishart_process_.WishartProcess(time_on_axis='first', verbose=True).fit(data_list)\n",
    "\n",
    "wp.likelihood(wp.D_map)\n",
    "\n",
    "wp.loglikes_after_burnin.max()\n",
    "\n",
    "wp.store_precision = True\n",
    "\n",
    "wp.score(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm = dff.xs(n_dim_obs, level='dim', axis=1).xs(T, level='time')\n",
    "mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.abs(dff.estimator[100]['TGL'][10].precision_ - dff.estimator[100]['KTGL'][10].precision_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from decimal import Decimal\n",
    "' & '.join(['%.3f' % Decimal(i) for i in mm['MSE_precision']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff[[s for s in scores if s != 'estimator']].to_pickle(\"dff_setting_1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LTGL ($\\ell_2^2$)'].latent_])\n",
    "l2 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LTGL ($\\ell_1$)'].latent_])\n",
    "l3 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LVGLASSO'].L])\n",
    "\n",
    "l4 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LTGL ($\\ell_2^2$)'].latent_])\n",
    "l5 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LTGL ($\\ell_1$)'].latent_])\n",
    "l6 = ([np.linalg.matrix_rank(r) for r in mm.estimator['LVGLASSO'].L])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1,l2,l3,l4,l5,l6 = utils.load_pickle(filename=\"ells.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2,1, sharey=False, figsize=(10,5), dpi=600)\n",
    "\n",
    "colors = ['white', 'lightblue', 'C7']\n",
    "alpha = 0.95\n",
    "\n",
    "counter=collections.Counter(l1)\n",
    "ax1.bar(counter.keys(), np.array(counter.values())/len(l1), \n",
    "        alpha=alpha, width=0.24, label='LTGL ($\\ell_2^2$)', color=colors[0], edgecolor='k')\n",
    "counter=collections.Counter(l2)\n",
    "ax1.bar(np.array(counter.keys())+0.25, np.array(counter.values())/len(l1), \n",
    "        alpha=alpha, width=0.24, label='LTGL ($\\ell_1$)', color=colors[1], edgecolor='k')\n",
    "counter=collections.Counter(l3)\n",
    "ax1.bar(np.array(counter.keys())-0.25, np.array(counter.values())/len(l1), \n",
    "        alpha=alpha, width=0.24, label='LVGLASSO', color=colors[2], edgecolor='k')\n",
    "\n",
    "ax1.set_xticks(range(0,30, 2))\n",
    "#ax1.set_ylim(0,5)\n",
    "ax1.axvline(20, c='r', ls='--')\n",
    "ax1.set_xlabel(r'ranks of L obtained with ($p_2$)')\n",
    "ax1.set_ylabel('frequency')\n",
    "# ax1.set_xscale(\"log\")\n",
    "# ax1.set_xlim([10, 100])\n",
    "ax1.xaxis.label.set_size(15)\n",
    "ax1.yaxis.label.set_size(15)\n",
    "\n",
    "#ax1.legend()\n",
    "# ax0.legend(prop={'size': 10})\n",
    "# ax0.set_title('bars with legend')\n",
    "\n",
    "\n",
    "counter=collections.Counter(l4)\n",
    "ax2.bar(counter.keys(), np.array(counter.values())/len(l4), \n",
    "        alpha=alpha, width=0.24, label='LTGL ($\\ell_2^2$)', color=colors[0], edgecolor='k')\n",
    "counter=collections.Counter(l5)\n",
    "ax2.bar(np.array(counter.keys())+0.25,  \n",
    "        np.array(counter.values())/len(l4), alpha=alpha, width=0.24, label='LTGL ($\\ell_1$)', color=colors[1],\n",
    "        edgecolor='k')\n",
    "counter=collections.Counter(l6)\n",
    "ax2.bar(np.array(counter.keys())-0.25,  \n",
    "        np.array(counter.values())/len(l4), alpha=alpha, width=0.24, label='LVGLASSO', color=colors[2],\n",
    "       edgecolor='k')\n",
    "\n",
    "ax2.set_xticks(range(0,30,2))\n",
    "# ax2.set_xlim(2.5,6.7)\n",
    "ax2.set_xlabel(r'ranks of L obtained with ($p_1$)')\n",
    "ax2.set_ylabel('frequency')\n",
    "ax2.xaxis.label.set_size(15)\n",
    "ax2.yaxis.label.set_size(15)\n",
    "ax2.axvline(5, c='r', ls='--')\n",
    "ax1.legend(loc='upper left', fontsize='x-large')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "f.savefig(\"ranks_distribution_vertical.pdf\", dpi=600, transparent=True, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True, figsize=(10,2.6), dpi=600)\n",
    "\n",
    "colors = ['white', 'lightblue', 'C7']\n",
    "alpha = 0.5\n",
    "\n",
    "counter=collections.Counter(l1)\n",
    "ax1.plot(range(len(l1)), l1, \n",
    "        alpha=alpha, label='LTGL ($\\ell_2^2$)', color=colors[0])\n",
    "counter=collections.Counter(l2)\n",
    "ax1.plot(np.arange(len(l1))+.2, l2, \n",
    "        alpha=alpha,  label='LTGL ($\\ell_1$)', color=colors[1])\n",
    "counter=collections.Counter(l3)\n",
    "ax1.plot(np.arange(len(l1))+.4, l3,\n",
    "        alpha=alpha, label='LVGLASSO', color=colors[2])\n",
    "\n",
    "# ax1.set_xticks(range(15,25, 1))\n",
    "#ax1.set_ylim(0,5)\n",
    "ax1.axhline(20, c='r', ls='--')\n",
    "ax1.set_xlabel(r'ranks of L obtained with ($p_2$)')\n",
    "ax1.set_ylabel('frequency')\n",
    "ax1.xaxis.label.set_size(15)\n",
    "ax1.yaxis.label.set_size(15)\n",
    "\n",
    "#ax1.legend()\n",
    "# ax0.legend(prop={'size': 10})\n",
    "# ax0.set_title('bars with legend')\n",
    "\n",
    "\n",
    "counter=collections.Counter(l4)\n",
    "ax2.plot(range(len(l4)), l4, \n",
    "        alpha=alpha,label='LTGL ($\\ell_2^2$)', color=colors[0])\n",
    "counter=collections.Counter(l5)\n",
    "ax2.plot(np.arange(len(l4))+.2, l5,\n",
    "        alpha=alpha,  label='LTGL ($\\ell_1$)', color=colors[1])\n",
    "counter=collections.Counter(l6)\n",
    "ax2.plot(np.arange(len(l4))+.4, l6, alpha=alpha,label='LVGLASSO', color=colors[2])\n",
    "\n",
    "# ax2.set_xticks(range(10))\n",
    "# ax2.set_xlim(2.5,6.7)\n",
    "ax2.set_xlabel(r'ranks of L obtained with ($p_1$)')\n",
    "ax2.xaxis.label.set_size(15)\n",
    "ax2.axhline(5, c='r', ls='--')\n",
    "ax1.legend(loc='best', fontsize='large')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
